{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from espm.conf import log_shift, dicotomy_tol, sigmaL\n",
    "from espm.utils import create_laplacian_matrix\n",
    "from espm.estimators import SmoothNMF\n",
    "from espm.models import ToyModel\n",
    "from copy import deepcopy\n",
    "from espm.weights import generate_weights as gw\n",
    "from espm.datasets.base import generate_spim_sample\n",
    "from espm.estimators.updates import initialize_algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "global_param = dict()\n",
    "global_param[\"l2\"] = False\n",
    "global_param[\"verbose\"]= 0\n",
    "global_param[\"tol\"] = 0\n",
    "global_param[\"max_iter\"] = 1000\n",
    "global_param[\"dicotomy_tol\"] = dicotomy_tol\n",
    "global_param[\"debug\"] = False\n",
    "global_param[\"log_shift\"] = log_shift \n",
    "global_param[\"eval_print\"] = 10\n",
    "global_param[\"hspy_comp\"] = False\n",
    "global_param[\"no_stop_criterion\"] = True\n",
    "global_param[\"init\"] = \"nndsvda\"\n",
    "\n",
    "seed = 0\n",
    "k = 3\n",
    "shape_2d = (25, 25)\n",
    "l = 25\n",
    "c = 10\n",
    "n_poisson=500\n",
    "lambda_L = 1000\n",
    "\n",
    "def create_toy_problem(l = 25, k = 3, shape_2d = [10, 10], c = 10, n_poisson=200, seed=0, force_simplex=True):\n",
    "    p = np.prod(shape_2d)\n",
    "    assert len(shape_2d) == 2\n",
    "    np.random.seed(seed)\n",
    "    H = np.random.rand(k,p)\n",
    "    if force_simplex:\n",
    "        H = H/np.sum(H, axis=0, keepdims=True)\n",
    "    \n",
    "    G = np.random.rand(l,c)\n",
    "    W = np.random.rand(c,k)\n",
    "    D = G @ W\n",
    "\n",
    "    X = D @ H\n",
    "\n",
    "    Xdot = 1/n_poisson * np.random.poisson(n_poisson * X)\n",
    "\n",
    "    return G, D, H, X, Xdot\n",
    "\n",
    "def get_toy_sample(l = 25, k = 3, shape_2d = [10, 10], c = 10, n_poisson=200, seed=0):\n",
    "    model_params = {\"L\": l, \"C\": c, \"K\": k, \"seed\": seed}\n",
    "    # densities = np.random.uniform(0.1, 2.0, 3)\n",
    "    densities = np.ones([k])\n",
    "    misc_params = {\"N\": n_poisson, \"seed\": seed, 'densities' : densities, \"model\": \"ToyModel\"}\n",
    "\n",
    "    toy_model = ToyModel(**model_params)\n",
    "    toy_model.generate_phases()\n",
    "    phases = toy_model.phases.T\n",
    "    weights = gw.generate_weights(\"laplacian\", shape_2d=shape_2d, k=k, seed=seed)\n",
    "\n",
    "    sample = generate_spim_sample(phases, weights, model_params,misc_params, seed = seed)\n",
    "    return sample\n",
    "\n",
    "def create_laplacian_problem(l = 25, k = 3, shape_2d = [10, 10], c = 10, n_poisson=200, seed=0):\n",
    "    sample = get_toy_sample(l=l, k =k, shape_2d = shape_2d, c=c, n_poisson=n_poisson, seed=seed)\n",
    "    def to_vec(X):\n",
    "        n = X.shape[2]\n",
    "        return X.transpose(2,0,1).reshape(n, -1)\n",
    "    D = sample[\"GW\"].T\n",
    "    G = sample[\"G\"]\n",
    "    H = to_vec(sample[\"H\"])\n",
    "    X = to_vec(sample[\"X\"])\n",
    "    Xdot = to_vec(sample[\"Xdot\"])\n",
    "    shape_2d = sample[\"shape_2d\"]\n",
    "\n",
    "    return G, D, H, X, Xdot\n",
    "\n",
    "\n",
    "def one_experiment(X, experiment_param, algo_param, global_param):\n",
    "    est = SmoothNMF(**algo_param, **experiment_param, **global_param)\n",
    "    force_simplex_init = True\n",
    "    if force_simplex_init:\n",
    "        _, W0, H0 = initialize_algorithms(X, est.G, None, None, n_components=est.n_components, init=est.init, random_state=est.random_state, force_simplex=True, logshift=log_shift)\n",
    "        W = est.fit_transform(X, W=W0, H=H0)\n",
    "    else:\n",
    "        W = est.fit_transform(X)\n",
    "    H = est.H_\n",
    "    losses = est.get_losses()\n",
    "    loss = losses[\"full_loss\"].copy()\n",
    "    final_loss = loss[-1]\n",
    "    gamma = losses[\"gamma\"].copy()\n",
    "    return loss, final_loss, W.copy(), H.copy(), gamma\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment_set(laplacian, noise, force_simplex):\n",
    "\n",
    "    if laplacian:\n",
    "        G, D, H, X, Xdot = create_laplacian_problem(l=l, k =k, shape_2d = shape_2d, c=c, n_poisson=n_poisson, seed=seed)\n",
    "    else:\n",
    "        G, D, H, X, Xdot = create_toy_problem(l=l, k =k, shape_2d = shape_2d, c=c, n_poisson=n_poisson, seed=seed)\n",
    "\n",
    "    if noise:\n",
    "        Y = X\n",
    "    else:\n",
    "        Y = Xdot\n",
    "\n",
    "    true_D = D\n",
    "    true_H = H\n",
    "    L = create_laplacian_matrix(*shape_2d)\n",
    "\n",
    "    # experiment parameters\n",
    "    experiment_param = dict()\n",
    "    experiment_param[\"force_simplex\"] = force_simplex\n",
    "    experiment_param[\"lambda_L\"] = lambda_L \n",
    "    experiment_param[\"mu\"] = 0\n",
    "    experiment_param[\"epsilon_reg\"] = 1\n",
    "    experiment_param[\"normalize\"] = False\n",
    "    experiment_param[\"G\"] = None\n",
    "    experiment_param[\"shape_2d\"] = shape_2d\n",
    "    experiment_param[\"n_components\"] = k\n",
    "    experiment_param[\"true_D\"] = true_D\n",
    "    experiment_param[\"true_H\"] = true_H\n",
    "    experiment_param[\"random_state\"] = seed\n",
    "\n",
    "    losses = []\n",
    "    final_losses = []\n",
    "    Ws = []\n",
    "    Hs = []\n",
    "    params = []\n",
    "    captions = []\n",
    "    gammas = []\n",
    "    if laplacian:\n",
    "        algos = [\"log_surrogate\", \"l2_surrogate\"]\n",
    "    else:\n",
    "        algos = [\"log_surrogate\", \"l2_surrogate\", \"projected_gradient\"]\n",
    "    \n",
    "    for algo in algos:\n",
    "        for linesearch in [False, True]:\n",
    "            # for sL in [sigmaL/4, sigmaL/2, sigmaL]:\n",
    "            for sL in [sigmaL]:\n",
    "                # algo parameters\n",
    "                algo_param = dict()\n",
    "                algo_param[\"linesearch\"] = linesearch\n",
    "                algo_param[\"algo\"] = algo\n",
    "                # algo_param[\"gamma\"] = sL\n",
    "                if algo == \"projected_gradient\":\n",
    "                    algo_param[\"gamma\"] = [500*sL, 500*sL]\n",
    "                else:\n",
    "                    algo_param[\"gamma\"] = sL\n",
    "                params.append(deepcopy([experiment_param, algo_param, global_param]))\n",
    "\n",
    "                loss, final_loss, W, H, gamma = one_experiment(Y, experiment_param, algo_param, global_param)\n",
    "                losses.append(loss)\n",
    "                final_losses.append(final_loss)\n",
    "                Ws.append(W)\n",
    "                Hs.append(H)\n",
    "                gammas.append(gamma)\n",
    "                cl = \"\" if linesearch else \"no\"\n",
    "                # captions.append(f\"{algo} - {cl} linesearch - $\\gamma_0$={sL}\")\n",
    "                captions.append(f\"{algo} - {cl} linesearch\")\n",
    "\n",
    "    i = np.argmin(final_losses)\n",
    "    global_param_m = deepcopy(global_param)\n",
    "    global_param_m[\"max_iter\"] = global_param_m[\"max_iter\"]*3\n",
    "    loss, l_infty, W, H, _ = one_experiment(Y, experiment_param, params[i][1], global_param_m)       \n",
    "    np.testing.assert_array_equal(loss[:len(losses[i])], losses[i])\n",
    "    # plt.plot(loss)\n",
    "    # plt.plot(losses[i])\n",
    "    # plt.yscale(\"log\")\n",
    "    return losses, final_losses, Ws, Hs, params, captions, gammas, l_infty, W, H, true_D, true_H, L, X, Xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_create_toy_problem():\n",
    "    k = 3\n",
    "    shape_2d = (25, 25)\n",
    "    l = 25\n",
    "    c = 10\n",
    "    n_poisson=200\n",
    "\n",
    "    for seed in range(3):\n",
    "        G, D, H, Xtrue, X = create_toy_problem(shape_2d=shape_2d, k=k, l=l, c=c, n_poisson=n_poisson, seed=seed)\n",
    "        G2, D2, H2, Xtrue2, X2 = create_toy_problem(shape_2d=shape_2d, k=k, l=l, c=c, n_poisson=n_poisson, seed=seed)\n",
    "        np.testing.assert_array_equal(G, G2)\n",
    "        np.testing.assert_array_equal(D, D2)\n",
    "        np.testing.assert_array_equal(H, H2)\n",
    "        np.testing.assert_array_equal(Xtrue, Xtrue2)\n",
    "        np.testing.assert_array_equal(X, X2)\n",
    "\n",
    "        G3, D3, H3, Xtrue3, X3 = create_laplacian_problem(shape_2d=shape_2d, k=k, l=l, c=c, n_poisson=n_poisson, seed=seed)\n",
    "        G4, D4, H4, Xtrue4, X4 = create_laplacian_problem(shape_2d=shape_2d, k=k, l=l, c=c, n_poisson=n_poisson, seed=seed)   \n",
    "        np.testing.assert_array_equal(G3, G4)\n",
    "        np.testing.assert_array_equal(D3, D4)\n",
    "        np.testing.assert_array_equal(H3, H4)\n",
    "        np.testing.assert_array_equal(Xtrue3, Xtrue4)\n",
    "        np.testing.assert_array_equal(X3, X4)\n",
    "\n",
    "        assert G.shape == G3.shape == (l, c)\n",
    "        assert D.shape == D3.shape == (l, k)\n",
    "        assert H.shape == H3.shape == (k, np.prod(shape_2d))\n",
    "        assert Xtrue.shape == Xtrue3.shape == (l, np.prod(shape_2d))\n",
    "    \n",
    "test_create_toy_problem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "laplacian = True\n",
    "noise = True\n",
    "force_simplex = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, final_losses, Ws, Hs, params, captions, gammas, l_infty, W, H, true_D, true_H, L, X, Xdot = run_experiment_set(laplacian, noise, force_simplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 6])\n",
    "# plt.figure(figsize=[15, 10])\n",
    "\n",
    "for loss, caption in zip(losses, captions):\n",
    "    iterations = np.arange(len(loss))+1\n",
    "    if len(iterations)>10:\n",
    "        plt.plot(iterations, loss-l_infty, \".-\", label=caption)\n",
    "max_y = max([loss[0]-l_infty for loss in losses])\n",
    "min_y = min([loss[-1]-l_infty for loss in losses])\n",
    "plt.ylim([min_y, max_y])\n",
    "plt.xlim([1, len(loss)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma, caption in zip(gammas, captions):\n",
    "    iterations = np.arange(len(gamma))+1\n",
    "\n",
    "    plt.plot(iterations, gamma, \".\", label=caption)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hmat = H.reshape(k, shape_2d[0], shape_2d[1])\n",
    "Hmat_true = true_H.reshape(k, shape_2d[0], shape_2d[1])\n",
    "scale = 4\n",
    "cmap = plt.cm.viridis\n",
    "plt.figure(figsize=(scale*k,2*scale))\n",
    "for i in range(k):\n",
    "    plt.subplot(2,k,i+1)\n",
    "    plt.imshow(Hmat[i], cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(f\"Estimated H {i}\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(2,k,i+1+k)\n",
    "    plt.imshow(Hmat_true[i], cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(f\"True H {i}\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7ceffc662db6c9d514927743d8d35570797b920e33613212d4f424c0416cf91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
