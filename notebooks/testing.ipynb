{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from snmfem.experiments import load_samples, print_results, load_data, run_experiment\n",
    "from snmfem.measures import KL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_toy_problem(l = 25, k = 3, p = 100, c = 10, n_poisson=200, force_simplex=True,**kwargs):\n",
    "\n",
    "    A = np.random.rand(k,p)\n",
    "    if force_simplex:\n",
    "        A = A/np.sum(A, axis=0, keepdims=True)\n",
    "    \n",
    "    G = np.random.rand(l,c)\n",
    "    P = np.random.rand(c,k)\n",
    "    GP = G @ P\n",
    "\n",
    "    X = GP @ A\n",
    "\n",
    "    Xdot = 1/n_poisson * np.random.poisson(n_poisson * X)\n",
    "\n",
    "    return G, P, A, X, Xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dataset_toy.json\"\n",
    "n_sample = 0\n",
    "samples, k = load_samples(dataset)\n",
    "sample = samples[n_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xflat, true_spectra, true_maps, G, shape_2d = load_data(sample)\n",
    "Xtrue = true_spectra.T @ true_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2d = [6, 10]\n",
    "k = 5\n",
    "n_poisson = 30\n",
    "G, P, true_maps, Xtrue, Xflat = create_toy_problem(p = shape_2d[0]*shape_2d[1], k=k, n_poisson=n_poisson)\n",
    "true_spectra = (G @ P).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxit = 10\n",
    "tol = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for me random was the best initialization...\n",
    "default_params = {\n",
    "    \"n_components\" : k,\n",
    "    \"tol\" : tol,\n",
    "    \"max_iter\" : maxit,\n",
    "    \"init\" : \"random\",\n",
    "    \"random_state\" : 1,\n",
    "    \"verbose\" : 1\n",
    "    }\n",
    "\n",
    "params_snmf = {\n",
    "    \"force_simplex\" : True,\n",
    "    \"skip_G\" : False,\n",
    "    \"mu\": 0\n",
    "}\n",
    "\n",
    "params_evalution = {\n",
    "    \"u\" : True,\n",
    "}\n",
    "\n",
    "# All parameters are contained here\n",
    "exp = {\"name\": \"snmfem smooth 30\", \"method\": \"SmoothNMF\", \"params\": {**default_params, **params_snmf, \"lambda_L\" : 0}}\n",
    "\n",
    "m, (GP, A), loss  = run_experiment(Xflat, true_spectra, true_maps, G, exp, params_evalution,shape_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KL(Xflat, Xtrue, average=True))\n",
    "print(KL(Xflat, GP @ A, average=True))\n",
    "print(KL(Xtrue, GP @ A, average=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for me random was the best initialization...\n",
    "default_params = {\n",
    "    \"n_components\" : k,\n",
    "    \"tol\" : tol,\n",
    "    \"max_iter\" : maxit,\n",
    "    \"init\" : \"random\",\n",
    "    \"random_state\" : 1,\n",
    "    \"verbose\" : 1\n",
    "    }\n",
    "\n",
    "params_snmf = {\n",
    "    \"force_simplex\" : False,\n",
    "    \"skip_G\" : False,\n",
    "    \"mu\": 0\n",
    "}\n",
    "\n",
    "params_evalution = {\n",
    "    \"u\" : True,\n",
    "}\n",
    "\n",
    "# All parameters are contained here\n",
    "exp = {\"name\": \"snmfem smooth 30\", \"method\": \"SmoothNMF\", \"params\": {**default_params, **params_snmf, \"lambda_L\" : 0}}\n",
    "\n",
    "m2, (GP2, A2), loss2  = run_experiment(Xflat, true_spectra, true_maps, G, exp, params_evalution,shape_2d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "for i,  l in enumerate([loss, loss2]):\n",
    "    names = list(l.dtype.names)\n",
    "    values = np.array([list(e) for e in l])\n",
    "\n",
    "    # axes[0].plot(values[:,1:-2], markersize=3.5)\n",
    "    axes[i,0].plot(values[:,1],'b',markersize=3.5)\n",
    "    axes[i,0].plot(values[:,0],'r--',markersize=3.5)\n",
    "    # axes[i,0].plot(values[:,-1],'g-',markersize=3.5)\n",
    "    axes[i,0].set_yscale(\"log\")\n",
    "    axes[i,0].set_xlabel(\"number of iterations\")\n",
    "    # axes[0].legend(names[1:-2] + [names[0]])\n",
    "    axes[i,0].legend([names[1]] + [names[0]])\n",
    "    # axes[i,0].legend([names[1]] + [names[0]] +[names[-1]])\n",
    "    axes[i,0].set_title(\"Losses\")\n",
    "\n",
    "    axes[i,1].plot(values[:,4:6], markersize=3.5)\n",
    "    axes[i,1].legend(names[4:6])\n",
    "    axes[i,1].set_xlabel(\"number of iterations\")\n",
    "    axes[i,1].set_title(\"Evolution of A and P\")\n",
    "    axes[i,1].set_yscale(\"log\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting parameters\n",
    "fontsize = 15\n",
    "aspect_ratio = 3/4\n",
    "scale = 20\n",
    "cmap = plt.cm.gist_heat_r\n",
    "vmin = 0\n",
    "vmax = np.max(true_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = np.array(m[:-1])\n",
    "order = np.array(m[-1])\n",
    "\n",
    "fig, axes = plt.subplots(k,3,figsize = (scale, scale/3*k * aspect_ratio))\n",
    "\n",
    "\n",
    "for j in range(k):\n",
    "    ind = np.arange(k)[order[0,j]]\n",
    "    axes[j, 0].plot(true_spectra[j],'bo',label='truth',linewidth=4)\n",
    "    axes[j, 0].plot(GP[:,ind] ,'r-',label='reconstructed',markersize=3.5)\n",
    "    axes[j, 0].set_title(\"{:.2f} deg\".format(metric[0,j]))\n",
    "\n",
    "for j in range(k):\n",
    "    ind = np.arange(k)[order[1,j]]\n",
    "    axes[j, 1].imshow(A[ind].reshape(*shape_2d), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    axes[j, 1].set_title(\"Mse: {:.2f}\".format(metric[1,j]))\n",
    "    axes[j, 2].imshow(true_maps[j].reshape(*shape_2d), vmin=vmin, vmax=vmax, cmap=cmap)   \n",
    "    \n",
    "rows = ['Phase {}'.format(col) for col in range(k)]\n",
    "cols = [\"Phase\", \"Map\", \"Real map\"]\n",
    "\n",
    "for ax, col in zip(axes[0], cols):\n",
    "    ax.set_title(col, fontsize=fontsize)\n",
    "\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, fontsize=fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = np.array(m2[:-1])\n",
    "order = np.array(m2[-1])\n",
    "\n",
    "fig, axes = plt.subplots(k,3,figsize = (scale, scale/3*k * aspect_ratio))\n",
    "\n",
    "\n",
    "for j in range(k):\n",
    "    ind = np.arange(k)[order[0,j]]\n",
    "    axes[j, 0].plot(true_spectra[j],'bo',label='truth',linewidth=4)\n",
    "    axes[j, 0].plot(GP2[:,ind] ,'r-',label='reconstructed',markersize=3.5)\n",
    "    axes[j, 0].set_title(\"{:.2f} deg\".format(metric[0,j]))\n",
    "\n",
    "for j in range(k):\n",
    "    ind = np.arange(k)[order[1,j]]\n",
    "    axes[j, 1].imshow(A2[ind].reshape(*shape_2d), vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    axes[j, 1].set_title(\"Mse: {:.2f}\".format(metric[1,j]))\n",
    "    axes[j, 2].imshow(true_maps[j].reshape(*shape_2d), vmin=vmin, vmax=vmax, cmap=cmap)   \n",
    "    \n",
    "rows = ['Phase {}'.format(col) for col in range(k)]\n",
    "cols = [\"Phase\", \"Map\", \"Real map\"]\n",
    "\n",
    "# for ax, col in zip(axes[0], cols):\n",
    "#     ax.set_title(col, fontsize=fontsize)\n",
    "\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, fontsize=fontsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "source": [
    "# Other stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunlocbox import functions\n",
    "from pyunlocbox.solvers import mlfbf, solve\n",
    "from snmfem.conf import log_shift\n",
    "# Let us solve the following problem\n",
    "# \n",
    "# \\argmin_P  - \\sum_ij  X_ij log(GPA)_ij + (GPA)_ij  s.t. P \\geq 0\n",
    "\n",
    "# \\argmin_A  - \\sum_ij  X_ij log(GPA)_ij + (GPA)_ij + f(A) s.t. A \\geq 0\n",
    "\n",
    "\n",
    "# class smooth(functions.func):\n",
    "#     def __init__(self, G, A):\n",
    "#         self.A = A\n",
    "#         self.G = G\n",
    "#         self.nabla = np.sum(self.G.T, axis=1, keepdims=True) @ np.sum(self.A.T, axis=0, keepdims=True)\n",
    "\n",
    "#     def _eval(self, P):\n",
    "#         return np.sum(self.G @ P @ self.A)\n",
    "#     def _grad(self, P):\n",
    "#         return self.nabla\n",
    "\n",
    "# f_smooth = smooth(G, A)\n",
    "# assert(f_smooth.grad(P).shape == P.shape)\n",
    "# np.testing.assert_allclose(f_smooth.grad(P),f_smooth.grad(2*P))\n",
    "\n",
    "\n",
    "class mxlogvpv(functions.func):\n",
    "    def __init__(self, X, lambda_=1, log_shift=log_shift, **kwargs):\n",
    "        super(mxlogvpv, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "        self.X = X\n",
    "        self.log_shift = log_shift\n",
    "        self.offset = np.sum(self.X * np.log(self.X+log_shift)) - np.sum(self.X)\n",
    "\n",
    "    def _eval(self, P):\n",
    "        return self.offset * (self.offset - self.lambda_ * np.sum(self.X * np.log(P+log_shift)) + np.sum(P))\n",
    "    def _prox(self, P, T):\n",
    "        gamma = self.lambda_ * T\n",
    "        delta = (P - gamma)**2 + 4 * gamma * self.X\n",
    "        return (P-gamma + np.sqrt(delta))/2\n",
    "\n",
    "def solve_P(G, A, X, **kwargs):\n",
    "    L = lambda P : G @ P @ A\n",
    "    Lt = lambda X: G.T @ X @ A.T \n",
    "\n",
    "    f = functions.proj_positive()\n",
    "    g = mxlogvpv(X)\n",
    "    h = functions.dummy()\n",
    "    beta = 0\n",
    "    mu = beta + np.linalg.norm(G,2) * np.linalg.norm(A,2)\n",
    "    step = 1 / mu / 2\n",
    "\n",
    "    x0 = np.zeros(P.shape)\n",
    "    D = np.linalg.lstsq(A.T, X.T)[0].T\n",
    "    x0 = np.abs(np.linalg.lstsq(G, D)[0])\n",
    "    d0 = np.zeros(X.shape)\n",
    "\n",
    "    solver = mlfbf(step=step, L=L, Lt=Lt, d0=d0 )\n",
    "    ret = solve([f, g, h], x0, solver, **kwargs)\n",
    "\n",
    "    sol = ret[\"sol\"], np.array(ret[\"objective\"]).sum(axis=1)\n",
    "    return sol\n",
    "\n",
    "def solve_A(G, P, X, **kwargs):\n",
    "    GP = G @ P\n",
    "    L = lambda A : GP @ A\n",
    "    Lt = lambda X: GP.T @ X\n",
    "    \n",
    "    n = GP.shape[1]\n",
    "    opA = lambda A: np.sum(A, 0, keepdims=True)\n",
    "    opAt = lambda V: np.ones([n,1]) @ V\n",
    "    y = np.ones([1, X.shape[1]])\n",
    "\n",
    "    f = functions.proj_positive()\n",
    "    g = mxlogvpv(X)\n",
    "    h = function.norm_l2(A=OpA, At=OpAt, y=y)\n",
    "    beta = 0\n",
    "    mu = beta + np.linalg.norm(G,2) * np.linalg.norm(A,2)\n",
    "    step = 1 / mu / 2\n",
    "\n",
    "    x0 = np.zeros(P.shape)\n",
    "    D = np.linalg.lstsq(A.T, X.T)[0].T\n",
    "    x0 = np.abs(np.linalg.lstsq(G, D)[0])\n",
    "    d0 = np.zeros(X.shape)\n",
    "\n",
    "    solver = mlfbf(step=step, L=L, Lt=Lt, d0=d0 )\n",
    "    ret = solve([f, g, h], x0, solver, **kwargs)\n",
    "\n",
    "    sol = ret[\"sol\"], np.array(ret[\"objective\"]).sum(axis=1)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol,  objective = solve_P(G, A, X, maxit=1000, rtol=1e-15)\n",
    "\n",
    "plt.plot(objective)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "np.linalg.norm(sol - P, \"fro\") / np.linalg.norm(P, \"fro\"), KLdiv(X, G @ sol, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = np.linalg.lstsq(A.T, Xdot.T)[0].T\n",
    "# x0 = np.abs(np.linalg.lstsq(G, D)[0])\n",
    "# D, np.linalg.lstsq(G, D)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol,  objective = solve_P(G, A, Xdot, maxit=100, rtol=1e-15)\n",
    "\n",
    "plt.plot(objective)\n",
    "# plt.yscale(\"log\")\n",
    "\n",
    "np.linalg.norm(sol - P, \"fro\") / np.linalg.norm(P, \"fro\"), KLdiv(X, G @ sol, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunlocbox import functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = NMF(G=G, n_components=k, debug=True, max_iter=200,  force_simplex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ps, As = est.fit_transform(X, eval_print=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = NMF(G=G, n_components=k, debug=True, max_iter=2000, force_simplex=False)\n",
    "# Pss, Ass = est.fit_transform(Xdot, eval_print=200)\n",
    "# Ainit = Ass/np.sum(Ass, axis=0, keepdims=True)\n",
    "        # - 'random': non-negative random matrices, scaled with:\n",
    "        #     sqrt(X.mean() / n_components)\n",
    "        # - 'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)\n",
    "        #     initialization (better for sparseness)\n",
    "        # - 'nndsvda': NNDSVD with zeros filled with the average of X\n",
    "        #     (better when sparsity is not desired)\n",
    "        # - 'nndsvdar': NNDSVD with zeros filled with small random values\n",
    "        #     (generally faster, less accurate alternative to NNDSVDa\n",
    "        #     for when sparsity is not desired)\n",
    "est = NMF(G=G, n_components=k, debug=True, mu=0, max_iter=2000,tol=0, force_simplex=False, init=\"nndsvd\")\n",
    "Pss, Ass = est.fit_transform(Xdot, eval_print=200)\n",
    "# np.sum(Ass, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = NMF(G=G, n_components=k, debug=True, max_iter=10, force_simplex=True)\n",
    "# Pss, Ass = est.fit_transform(Xdot, A=A, eval_print=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(A, vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(Ass, vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(Ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "num = np.random.rand(k,23)/20\n",
    "denum = np.random.rand(k,23)\n",
    "\n",
    "def f(nu):\n",
    "    sol = 0\n",
    "    for n,d in zip(num, denum):\n",
    "        sol = sol + n/(d+nu)\n",
    "    return sol - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.sum(num/denum, axis=0)\n",
    "# t = np.sum(num)\n",
    "# if r<1:\n",
    "#     bmax = 0\n",
    "# else:\n",
    "ind_min = np.argmax(num/denum, axis=0)\n",
    "ind_min2 = np.argmin(denum, axis=0)\n",
    "ind = np.arange(len(ind_min))\n",
    "\n",
    "bmin1 = num[ind_min, ind]-denum[ind_min, ind]\n",
    "bmin2 = num[ind_min2, ind]-denum[ind_min2, ind]\n",
    "bmin = np.maximum(bmin1, bmin2)\n",
    "bmax = r\n",
    "\n",
    "# nu = np.arange(bmin, bmax, 1e-3)\n",
    "# plt.plot(nu, f(nu))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmin, bmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_max = np.argmin(num/denum)\n",
    "num[ind_max]/denum[ind_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implements three algorithms for projecting a vector onto the simplex: sort, pivot and bisection.\n",
    "For details and references, see the following paper:\n",
    "Large-scale Multiclass Support Vector Machine Training via Euclidean Projection onto the Simplex\n",
    "Mathieu Blondel, Akinori Fujino, and Naonori Ueda.\n",
    "ICPR 2014.\n",
    "http://www.mblondel.org/publications/mblondel-icpr2014.pdf\n",
    "\"\"\"\n",
    "\n",
    "# To check for exact projection\n",
    "# https://github.com/RoyiAvital/StackExchangeCodes/blob/master/Mathematics/Q2327504/ProjectSimplexExact.m\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def projection_simplex_sort(v, z=1):\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w\n",
    "\n",
    "\n",
    "def projection_simplex_pivot(v, z=1, random_state=None):\n",
    "    rs = np.random.RandomState(random_state)\n",
    "    n_features = len(v)\n",
    "    U = np.arange(n_features)\n",
    "    s = 0\n",
    "    rho = 0\n",
    "    while len(U) > 0:\n",
    "        G = []\n",
    "        L = []\n",
    "        k = U[rs.randint(0, len(U))]\n",
    "        ds = v[k]\n",
    "        for j in U:\n",
    "            if v[j] >= v[k]:\n",
    "                if j != k:\n",
    "                    ds += v[j]\n",
    "                    G.append(j)\n",
    "            elif v[j] < v[k]:\n",
    "                L.append(j)\n",
    "        drho = len(G) + 1\n",
    "        if s + ds - (rho + drho) * v[k] < z:\n",
    "            s += ds\n",
    "            rho += drho\n",
    "            U = L\n",
    "        else:\n",
    "            U = G\n",
    "    theta = (s - z) / float(rho)\n",
    "    return np.maximum(v - theta, 0)\n",
    "\n",
    "\n",
    "def projection_simplex_bisection(v, z=1, tau=0.0001, max_iter=1000):\n",
    "    lower = 0\n",
    "    upper = np.max(v)\n",
    "    current = np.inf\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        if np.abs(current) / z < tau and current < 0:\n",
    "            break\n",
    "\n",
    "        theta = (upper + lower) / 2.0\n",
    "        w = np.maximum(v - theta, 0)\n",
    "        current = np.sum(w) - z\n",
    "        if current <= 0:\n",
    "            upper = theta\n",
    "        else:\n",
    "            lower = theta\n",
    "    return w\n",
    "\n",
    "n = 10\n",
    "rs = np.random.RandomState(0)\n",
    "v = rs.rand(n)\n",
    "z = 1\n",
    "print(z)\n",
    "\n",
    "w1 = projection_simplex_sort(v, z)\n",
    "print(np.sum(w1))\n",
    "\n",
    "w2 = projection_simplex_pivot(v, z)\n",
    "print(np.sum(w2))\n",
    "\n",
    "w3 = projection_simplex_bisection(v, z)\n",
    "print(np.sum(w3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aop = lambda x : np.sum(x)\n",
    "pinvA = np.linalg.pinv(np.ones([1,n]))\n",
    "pinvAop = lambda x: 1/n * x\n",
    "\n",
    "def mysolution(x):\n",
    "    return x - pinvAop(Aop(x) - 1)\n",
    "mysolution(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Divergence de Bregman"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.5*(x - 2)**2\n",
    "\n",
    "def nablaf(x):\n",
    "    return (x - 2)\n",
    "\n",
    "def f(x):\n",
    "    return np.abs(x - 2)\n",
    "\n",
    "def nablaf(x):\n",
    "    return np.sign(x - 2)\n",
    "\n",
    "def bregman_div(f, nablaf, xt, x):\n",
    "    fxt = f(xt)\n",
    "    fx = f(x)\n",
    "    nablafxt = nablaf(xt)\n",
    "    return fx - fxt - nablafxt * (x - xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10,10, 0.1)\n",
    "xt = -2\n",
    "fx = f(x)\n",
    "vmin = np.min(fx)\n",
    "vmax = np.max(fx)\n",
    "plt.plot(x, fx, label=\"f(x)\")\n",
    "plt.plot(x, bregman_div(f, nablaf, xt, x), label=\"Bregman divergence of f(x) at xt={}\".format(xt))\n",
    "plt.plot([xt, xt], [vmin, vmax], label=\"xt\")\n",
    "plt.ylim([vmin, vmax])\n",
    "plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmfem.updates import update_q\n",
    "from snmfem.conf import log_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('SNMF_EDXS-FwWDtlwS': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "1c54570ff4268047c81dd2c61765206f7b22026564b587a11579858717e9a312"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}