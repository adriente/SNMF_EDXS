{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('SNMF_EDXS')",
   "metadata": {
    "interpreter": {
     "hash": "508ccdc6fb5be5f7fd5f6d84709a2756aa123300835f386535c0d36e037b0594"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from snmfem.conf import DATASETS_PATH\n",
    "\n",
    "from snmfem.models import EDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an EDXS model\n",
    "model_parameters = {\"params_dict\" : {\"c0\" : 4.8935e-05, \n",
    "                                          \"c1\" : 1464.19810,\n",
    "                                          \"c2\" : 0.04216872,\n",
    "                                          \"b0\" : 0.15910789,\n",
    "                                          \"b1\" : -0.00773158,\n",
    "                                          \"b2\" : 8.7417e-04},\n",
    "                         \"db_name\" : \"simple_xrays_threshold.json\",\n",
    "                         \"e_offset\" : 0.208,\n",
    "                         \"e_scale\" : 0.01,\n",
    "                         \"e_size\": 1980,\n",
    "                         \"width_slope\" : 0.01,\n",
    "                         \"width_intercept\" : 0.065,\n",
    "                         \"seed\" : 1}\n",
    "model = EDXS(**model_parameters)\n",
    "e = model.x"
   ]
  },
  {
   "source": [
    "You need to run the script `python script/generate_synthetic_dataset.py` in order to get the data for the next cell."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an EDXS sample\n",
    "sample = DATASETS_PATH / Path(\"aspim037_N100_2ptcls_brstlg\") / Path(\"sample_0.npz\")\n",
    "# load data\n",
    "data = np.load(sample)\n",
    "X = data[\"X\"]\n",
    "Xdot = data[\"Xdot\"]\n",
    "nx, ny, ns = X.shape\n",
    "Xflat = X.transpose([2,0,1]).reshape(ns, nx*ny)\n",
    "Xdotflat = Xdot.transpose([2,0,1]).reshape(ns, nx*ny)\n",
    "densities = data[\"densities\"]\n",
    "phases = data[\"phases\"]\n",
    "true_spectra = np.expand_dims(densities, axis=1) * phases\n",
    "true_maps = data[\"weights\"]\n",
    "k = true_maps.shape[2]\n",
    "true_maps_flat = true_maps.transpose([2,0,1]).reshape(k,nx*ny)\n",
    "assert(true_maps.shape[:2] == (nx, ny))\n",
    "G = data[\"G\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-1ddbb7fba7c4>:2: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  GP = np.linalg.lstsq(A.T, Xflat.T)[0]\n",
      "<ipython-input-5-1ddbb7fba7c4>:3: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(G, GP.T)[0]\n"
     ]
    }
   ],
   "source": [
    "A = true_maps.reshape(-1, true_maps.shape[2]).T\n",
    "GP = np.linalg.lstsq(A.T, Xflat.T)[0]\n",
    "P = np.linalg.lstsq(G, GP.T)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "c0 = 4.8935e-05\n",
    "c1 = 1464.19810\n",
    "c2 = 0.04216872\n",
    "b0 = 0.15910789\n",
    "b1 = -0.00773158\n",
    "b2 = 8.7417e-04"
   ]
  },
  {
   "source": [
    "# Numpy implementation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bmatrix(b0, b1, b2, c0, c1, c2, e):\n",
    "    beta = b0/e + b1 + b2*e\n",
    "    Gamma = np.exp(-c2 / e**3) * (1 - np.exp(-c1 / e**3))\n",
    "    alpha = e**3 * (1 - np.exp(- c0 / e**3)) / c0\n",
    "    B = np.expand_dims(beta * Gamma * alpha, axis=1 )\n",
    "    return B\n",
    "\n",
    "def loss(b0, b1, b2, c0, c1, c2, e, G, P, A, X):\n",
    "    B = Bmatrix(b0, b1, b2, c0, c1, c2, e)\n",
    "    GP = G @ P\n",
    "    GPA = (GP + B) @ A\n",
    "    return - np.mean(X*np.log(GPA)) + np.mean(GPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Bmatrix(b0, b1, b2, c0, c1, c2, e)\n",
    "l = loss(b0, b1, b2, c0, c1, c2, e, G, P, A, Xflat)\n"
   ]
  },
  {
   "source": [
    "# Torch implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c0 = Variable(torch.tensor(c0), requires_grad=True)\n",
    "t_c1 = Variable(torch.tensor(c1), requires_grad=True)\n",
    "t_c2 = Variable(torch.tensor(c2), requires_grad=True)\n",
    "t_b0 = Variable(torch.tensor(b0), requires_grad=True)\n",
    "t_b1 = Variable(torch.tensor(b1), requires_grad=True)\n",
    "t_b2 = Variable(torch.tensor(b2), requires_grad=True)\n",
    "\n",
    "t_e = Variable(torch.tensor(e), requires_grad=False)\n",
    "\n",
    "t_G = Variable(torch.tensor(G), requires_grad=False)\n",
    "t_P = Variable(torch.tensor(P), requires_grad=False)\n",
    "t_A = Variable(torch.tensor(A), requires_grad=False)\n",
    "t_X = Variable(torch.tensor(Xflat), requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_Bmatrix(b0, b1, b2, c0, c1, c2, e):\n",
    "    beta = b0/e + b1 + b2*e\n",
    "    Gamma = torch.exp(-c2 / e**3) * (1 - torch.exp(-c1 / e**3))\n",
    "    alpha = e**3 * (1 - torch.exp(- c0 / e**3)) / c0\n",
    "    B = torch.unsqueeze(beta * Gamma * alpha, axis=1 )\n",
    "    return B\n",
    "\n",
    "def torch_loss(b0, b1, b2, c0, c1, c2, e, G, P, A, X):\n",
    "    B = torch_Bmatrix(b0, b1, b2, c0, c1, c2, e)\n",
    "    GP = torch.matmul(G, P)\n",
    "    GPA = torch.matmul((GP + B), A )\n",
    "    return - torch.mean(X*torch.log(GPA)) + torch.mean(GPA)"
   ]
  },
  {
   "source": [
    "### Check that the forward functions gives the same results in torch and in numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.8819978976686354e-08"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "B_torch = torch_Bmatrix(t_b0, t_b1, t_b2, t_c0, t_c1, t_c2, t_e)\n",
    "\n",
    "np.linalg.norm(B - B_torch.detach().numpy())/np.linalg.norm(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.0345401822370927e-09"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "l_torch = torch_loss(t_b0, t_b1, t_b2, t_c0, t_c1, t_c2, t_e, t_G, t_P, t_A, t_X)\n",
    "\n",
    "np.linalg.norm(l - l_torch.detach().numpy())/np.linalg.norm(l)"
   ]
  },
  {
   "source": [
    "### Compute the gradients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(-0.0150),\n",
       " tensor(1.5216e-06),\n",
       " tensor(-0.0300),\n",
       " tensor(0.1057),\n",
       " tensor(0.4643),\n",
       " tensor(3.7720))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "t_c0.grad = torch.zeros(t_c0.size())\n",
    "t_c1.grad = torch.zeros(t_c1.size())\n",
    "t_c2.grad = torch.zeros(t_c2.size())\n",
    "t_b0.grad = torch.zeros(t_b0.size())\n",
    "t_b1.grad = torch.zeros(t_b1.size())\n",
    "t_b2.grad = torch.zeros(t_b2.size())\n",
    "\n",
    "l_torch = torch_loss(t_b0, t_b1, t_b2, t_c0, t_c1, t_c2, t_e, t_G, t_P, t_A, t_X)\n",
    "l_torch.backward()\n",
    "\n",
    "# here they are! The number are quite big indeed. That is likely to cause problem for the optimization...\n",
    "t_c0.grad, t_c1.grad, t_c2.grad, t_b0.grad, t_b1.grad,t_b2.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapman_brstlg(E, b0=None, b1=None, b2=None):\n",
    "        \"\"\"\n",
    "        Bremsstrahlung modelling function.\n",
    "        This function takes arguments to allow calculation with temporary values of the parameters.\n",
    "        See Chapman et al., 1984, J. of microscopy, vol. 136, pp. 171\n",
    "        \"\"\"\n",
    "        return (b0 / E + b1 + b2 * E) \n",
    "\n",
    "def detector(E, c1=None, c2=None):\n",
    "    \"\"\"\n",
    "    Detector modelling function.\n",
    "    This function takes arguments to allow calculation with temporary values of the parameters.\n",
    "    Absorption in the dead layer * Photons not absorbed in the detector\n",
    "    \"\"\"\n",
    "    return np.exp(-c2 / np.power(E, 3)) * (\n",
    "        1 - np.exp(-c1 / np.power(E, 3))\n",
    "    )\n",
    "\n",
    "def self_abs(E,c0=None):\n",
    "    \"\"\"\n",
    "    self-absorption modelling function.\n",
    "    This function takes arguments to allow calculation with temporary values of the parameters.\n",
    "    Phi rho z model with a constant Phi rho z function\n",
    "    \"\"\"\n",
    "    return (\n",
    "        np.power(E, 3)\n",
    "        * (1 - np.exp(-c0 / np.power(E, 3)))\n",
    "        / c0\n",
    "    )\n",
    "\n",
    "def calc_db0 (E,c0,c1,c2) :\n",
    "    return (1.0/E)* detector(E,c1,c2) * self_abs(E,c0) \n",
    "\n",
    "def calc_db1(E,c0,c1,c2):\n",
    "    \"\"\"\n",
    "    Partial derivative of B with respect to b1\n",
    "    \"\"\"\n",
    "    return detector(E,c1,c2) * self_abs(E,c0) \n",
    "\n",
    "def calc_db2(E,c0,c1,c2):\n",
    "    \"\"\"\n",
    "    Partial derivative of B with respect to b2\n",
    "    \"\"\"\n",
    "    return E * detector(E,c1,c2) * self_abs(E,c0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}