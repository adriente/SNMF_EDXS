{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from snmfem.experiments import load_samples, print_results, load_data, run_experiment\n",
    "from snmfem.measures import KL, trace_xtLx\n",
    "from snmfem.updates import multiplicative_step_a, multiplicative_step_p, multiplicative_step_aq\n",
    "from snmfem.conf import log_shift, dicotomy_tol\n",
    "from snmfem.laplacian import sigmaL, create_laplacian_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_toy_problem(l = 25, k = 3, p = 100, c = 10, n_poisson=200, force_simplex=True):\n",
    "\n",
    "    A = np.random.rand(k,p)\n",
    "    if force_simplex:\n",
    "        A = A/np.sum(A, axis=0, keepdims=True)\n",
    "    \n",
    "    G = np.random.rand(l,c)\n",
    "    P = np.random.rand(c,k)\n",
    "    GP = G @ P\n",
    "\n",
    "    X = GP @ A\n",
    "\n",
    "    Xdot = 1/n_poisson * np.random.poisson(n_poisson * X)\n",
    "\n",
    "    return G, P, A, X, Xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_l2_surrogate(At, A=None, sigmaL=sigmaL, lambda_L=1):\n",
    "    tmp = (At @ L)\n",
    "    t1 = np.sum(At * tmp)\n",
    "    if not(A is None):\n",
    "        t2 = np.sum(A * tmp)\n",
    "        t3 = np.sum((At-A)**2)\n",
    "    else:\n",
    "        t2 = t1\n",
    "        t3 = 0\n",
    "    return lambda_L / 2 * (2*t2 -t1 + sigmaL * t3)\n",
    "\n",
    "def diff_surrogate(At, A, sigmaL=sigmaL, lambda_L=1):\n",
    "    b_inf = trace_xtLx(L, A.T) * lambda_L / 2\n",
    "    b_supp = smooth_l2_surrogate(At, A=A, sigmaL=sigmaL, lambda_L=lambda_L)\n",
    "    return b_supp - b_inf\n",
    "    \n",
    "L = create_laplacian_matrix(4, 3)\n",
    "for i in range(10):\n",
    "    A1 = np.random.randn(3, 12)\n",
    "    v1 = smooth_l2_surrogate(A1)\n",
    "    v2 = smooth_l2_surrogate(A1, A1)\n",
    "    v3 = trace_xtLx(L, A1.T) / 2\n",
    "    np.testing.assert_almost_equal(v1, v2)\n",
    "    np.testing.assert_almost_equal(v1, v3)\n",
    "\n",
    "    for j in range(10):\n",
    "        A2 = np.random.randn(3, 12)\n",
    "        v4 = smooth_l2_surrogate(A1, A2)\n",
    "        v5 = trace_xtLx(L, A2.T) / 2\n",
    "        assert v4 >= v5\n",
    "        d = diff_surrogate(A1, A2, sigmaL=sigmaL)\n",
    "        np.testing.assert_almost_equal(v4 - v5 , d)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape_2d = [10, 15]\n",
    "k = 5\n",
    "n_poisson = 200\n",
    "G, P, A, Xtrue, X = create_toy_problem(p = shape_2d[0]*shape_2d[1], k=k, n_poisson=n_poisson)\n",
    "\n",
    "P1 = np.random.rand(*P.shape)\n",
    "A1 = np.random.rand(*A.shape)\n",
    "P2 = P1.copy()\n",
    "A2 = A1.copy()\n",
    "\n",
    "P3 = P1.copy()\n",
    "A3 = A1.copy()\n",
    "P0 = P1.copy()\n",
    "A0 = A1.copy()\n",
    "\n",
    "L = create_laplacian_matrix(*shape_2d)\n",
    "\n",
    "lambda_L = 10\n",
    "\n",
    "def loss(P, A):\n",
    "    DA = G @ P @ A\n",
    "    v1 = KL(X, DA) \n",
    "    v2 = trace_xtLx(L, A.T)\n",
    "    return v1 + lambda_L/2 * v2\n",
    "\n",
    "maxit = 100\n",
    "force_simplex = False\n",
    "loss0 = [loss(P0, A0)]\n",
    "\n",
    "loss1 = [loss(P1, A1)]\n",
    "loss2 = [loss(P2, A2)]\n",
    "diff_loss2 = []\n",
    "loss3 = [loss(P3, A3)]\n",
    "diff_loss3 = []\n",
    "\n",
    "# gamma2 = sigmaL\n",
    "gamma2 = 0.2\n",
    "gamma3 = sigmaL\n",
    "# gamma3 = 0.005\n",
    "gamma3_vec = [gamma3]\n",
    "d3 = []\n",
    "\n",
    "for i in range(maxit):\n",
    "    A0 = multiplicative_step_a(X, G, P0, A0, force_simplex=force_simplex, lambda_L=lambda_L, L=L)\n",
    "    P0 = multiplicative_step_p(X, G, P0, A0)\n",
    "    loss0.append(loss(P0, A0))\n",
    "    \n",
    "    A1 = multiplicative_step_aq(X, G, P1, A1, force_simplex=force_simplex, lambda_L=lambda_L, L=L)\n",
    "    P1 = multiplicative_step_p(X, G, P1, A1)\n",
    "    loss1.append(loss(P1, A1))\n",
    "\n",
    "    \n",
    "    A2 = multiplicative_step_aq(X, G, P2, A2, force_simplex=force_simplex, lambda_L=lambda_L, L=L, sigmaL=gamma2)\n",
    "    diff_loss2.append(loss2[-1]-loss(P2, A2))\n",
    "\n",
    "    P2 = multiplicative_step_p(X, G, P2, A2)\n",
    "    loss2.append(loss(P2, A2))\n",
    "    A3_old = A3.copy()\n",
    "    A3 = multiplicative_step_aq(X, G, P3, A3, force_simplex=force_simplex, lambda_L=lambda_L, L=L, sigmaL=gamma3)\n",
    "    d3.append(diff_surrogate(A3_old, A3, sigmaL=gamma3))\n",
    "    diff_loss3.append(d3)\n",
    "    if d3[-1]>0:\n",
    "        gamma3 = gamma3 / 1.2\n",
    "    else:\n",
    "        gamma3 = gamma3 * 1.5\n",
    "    gamma3_vec.append(gamma3)\n",
    "        \n",
    "    P3 = multiplicative_step_p(X, G, P3, A3)\n",
    "    loss3.append(loss(P3, A3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10*maxit):\n",
    "    A2 = multiplicative_step_aq(X, G, P2, A2, force_simplex=force_simplex, lambda_L=lambda_L, L=L, sigmaL=gamma2)\n",
    "    P2 = multiplicative_step_p(X, G, P2, A2)\n",
    "\n",
    "l_infty = loss(P2, A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = np.arange(maxit+1)+1\n",
    "plt.plot(iterations, np.array(loss0)-l_infty, \"kx-\", label=\"KL surrogate\")\n",
    "plt.plot(iterations, np.array(loss1)-l_infty, \"bx-\", label=\"L2 surrogate - theoretical step\")\n",
    "plt.plot(iterations, np.array(loss2)-l_infty, \"rx-\", label=\"L2 surrogate - optimal fixed step\")\n",
    "plt.plot(iterations, np.array(loss3)-l_infty, \"gx-\", label=\"L2 surrogate - linesearch\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gamma3_vec, \".-\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Evolution of the step size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicotomy problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(x, a, b, c):\n",
    "#     v = x + b\n",
    "#     return v - np.sqrt( v**2 + 4*a*c) +2*a \n",
    "# p = 1\n",
    "# x = np.arange(-2,2, 0.1)\n",
    "# a = np.random.rand(p)\n",
    "# a = 0.5\n",
    "# b = np.random.rand(p)\n",
    "# c = np.random.rand(p)\n",
    "# plt.plot(x, f(x,a,b,c))\n",
    "# plt.plot(x, np.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a1b43244e11bc51a1d0b046d5a6cc91cb73bf5187e443fb7c1433042d0ea61d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('SNMF_EDXS-FwWDtlwS': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
